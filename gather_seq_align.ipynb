{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c73ebe8-cc31-49ff-a082-924f8cbbf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9479d1-ead5-48b5-bedb-aedb67d94d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malaysian strain genome size: 18246\n"
     ]
    }
   ],
   "source": [
    "#for seq_record in SeqIO.parse(\"sequences/genome/AY029768.1_MYS.fasta\", \"fasta\"):\n",
    "for seq_record in SeqIO.parse(\"sequences/genome/NC_00278.1_MYS.fasta\", \"fasta\"):\n",
    "    \n",
    "    # just wanted to do a sanity check\n",
    "    print(f\"Malaysian strain genome size: {len(seq_record)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae679963-189d-47a6-87e8-40324dbfe8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangaldeshi strain genome size: 18252\n"
     ]
    }
   ],
   "source": [
    "for seq_record in SeqIO.parse(\"sequences/genome/AY988601.1_BGD.fasta\", \"fasta\"):\n",
    "    \n",
    "    # just wanted to do a sanity check\n",
    "    print(f\"Bangaldeshi strain genome size: {len(seq_record)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76692f9-7cdd-4d51-8687-0b9027609539",
   "metadata": {},
   "source": [
    "# 1. BLAST the glycoprotein and phosphoprotein sequences to get all sequences from NCBI\n",
    "\n",
    "Used reference sequences `sequences/PG/ref_G_seq` and `sequences/PG/ref_P_seq` for the glycoprotein and phosphoproteins. Queried these on BLAST using <i>Henipaviruses</i> as the search organism. \n",
    "\n",
    "83 full search results for G (could be individual protein, multiple, or full genome) stored at `sequences/PG/glyco_blast_83.fasta`, and 80 full search results for P stored at `sequences/PG/phospho_blast_80.fasta`. Removed duplicates in Geneious.\n",
    "\n",
    "Descriptions stored at `sequences/glyco_blast_descriptions.csv` and `sequences/phospho_blast_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678a03e-520d-4bc6-9aa4-904f9aef62bf",
   "metadata": {},
   "source": [
    "```bash\n",
    "bowtie2-build sequences/genome/AY029768.1_MYS_CDS.fna MYS_cds\n",
    "bowtie2 -x MYS_cds -f sequences/PG/G_seqs.fasta -S G_aln.sam\n",
    "```\n",
    "\n",
    "The sequence headers were updated, and the V, W, and C proteins were removed because they are duplicates of the phosphoprotein sequence. <b>This was found to cause problems when aligning the glycoprotein sequences</b>. It makes sense that you shouldn't have redundant sequences in a reference sequence, but I'm not sure why it didn't cause problems for the phosphoprotein alignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "611a7cd5-a1f7-44c7-8f22-dc87d1f6c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ncbi_accessions(id_list):\n",
    "    \n",
    "    #Entrez.email='skulkarni@g.harvard.edu'\n",
    "\n",
    "    # search Genbank, returns accession numbers\n",
    "    handle=Entrez.esearch(db='nucleotide', retmax=1000, term=\",\".join(id_list), idtype=\"acc\") \n",
    "    record = Entrez.read(handle)\n",
    "    \n",
    "    handle.close()\n",
    "    fetch = Entrez.efetch(db='nucleotide', id=\",\".join(record['IdList']), rettype='gb', retmode='text')\n",
    "    gb=fetch.read()\n",
    "    \n",
    "    # the first one is an empty string because it's what comes before the first locus\n",
    "    found_seq = list(gb.split(\"LOCUS\"))[1:]\n",
    "    print(f\"Found {len(found_seq)} out of {len(id_list)} NCBI accessions!\")\n",
    "    \n",
    "    # remove the sequences becuase they make the strings unnecessarily long\n",
    "    found_seq = [isolate.split(\"FEATURES\")[0] for isolate in found_seq]\n",
    "    \n",
    "    return found_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9a5184c1-2382-4895-9d98-b779b79b166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 out of 84 NCBI accessions!\n"
     ]
    }
   ],
   "source": [
    "glyco_found = get_ncbi_accessions(G_tree_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "513560c7-cded-46dc-8dc6-172620b0d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81 out of 81 NCBI accessions!\n"
     ]
    }
   ],
   "source": [
    "phospho_found = get_ncbi_accessions(P_tree_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ee679283-9f53-42bb-80b2-8a8c0d55013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "no_date_indices = [i for i in range(len(glyco_found)) if \"VRL\" not in glyco_found[i]]\n",
    "print(no_date_indices)\n",
    "\n",
    "no_date_indices = [i for i in range(len(phospho_found)) if \"VRL\" not in phospho_found[i]]\n",
    "print(no_date_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beca5a5-c44c-424c-8f9f-ddb194da0059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5468beb2-d481-498f-8bec-044c02cfa5ad",
   "metadata": {},
   "source": [
    "# 2. Single nucleotide polymorphism (SNP) calling\n",
    "\n",
    "## End goal is to convert the FASTA file into a VCF (variant calling format) file\n",
    "\n",
    "<b>Amazing tutorial:</b> https://www.ebi.ac.uk/sites/ebi.ac.uk/files/content.ebi.ac.uk/materials/2014/140217_AgriOmics/dan_bolser_snp_calling.pdf\n",
    "\n",
    "## Exact code to run for both P and G aligning to both reference genomes:\n",
    "\n",
    "```bash\n",
    "bash align_make_vcf.sh \"sequences/genome/AY988601.1_BGD_CDS.fna\" \"sequences/PG/P_seqs.fasta\" \"alignments\" \"P_BGD\"\n",
    "bash align_make_vcf.sh \"sequences/genome/NC_00278.1_MYS_CDS.fna\" \"sequences/PG/P_seqs.fasta\" \"alignments\" \"P_MYS\"\n",
    "\n",
    "bash align_make_vcf.sh \"sequences/genome/AY988601.1_BGD_CDS.fna\" \"sequences/PG/G_seqs.fasta\" \"alignments\" \"G_BGD\"\n",
    "bash align_make_vcf.sh \"sequences/genome/NC_00278.1_MYS_CDS.fna\" \"sequences/PG/G_seqs.fasta\" \"alignments\" \"G_MYS\"\n",
    "```\n",
    "\n",
    "The above bash script runs the following steps, adapted from the linked tutorial above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8acc6-9608-4bc2-b7f6-7894c41fa16b",
   "metadata": {},
   "source": [
    "<b></b>\n",
    "```bash\n",
    "bwa index sequences/genome/AY029768.1_MYS_CDS.fna\n",
    "```\n",
    "\n",
    "<b>Perform the alignment</b>\n",
    "```bash\n",
    "bwa aln sequences/genome/AY029768.1_MYS_CDS.fna sequences/PG/P_seqs.fasta > alignments/P_MYS_aln.sai\n",
    "```\n",
    "\n",
    "<b>Convert to SAM file format, which is human-readable</b>\n",
    "```bash\n",
    "bwa samse sequences/genome/AY029768.1_MYS_CDS.fna alignments/P_MYS_aln.sai sequences/PG/P_seqs.fasta > alignments/P_MYS_aln.sam\n",
    "```\n",
    "\n",
    "<b>Convert SAM to BAM and sort the BAM file</b>\n",
    "```bash\n",
    "   samtools view -b alignments/G_BGD_aln.sam > alignments/G_BGD_aln.bam\n",
    "   samtools sort alignments/G_BGD_aln.bam -o alignments/G_BGD_aln_sorted.bam\n",
    "```\n",
    "\n",
    "<b>Index the genome file again with `samtools`</b>\n",
    "```bash\n",
    "samtools faidx sequences/genome/AY029768.1_MYS_CDS.fna\n",
    "```\n",
    "\n",
    "<b>Run 'mpileup' to generate VCF format</b>\n",
    "```bash\n",
    "bcftools mpileup -f sequences/genome/AY988601.1_BGD_CDS.fna alignments/P_MYS_aln_sorted.bam > alignments/P_MYS_aln.bcf\n",
    "```\n",
    "\n",
    "<b>Call SNPs</b>\n",
    "```bash\n",
    "bcftools view -v snps alignments/P_MYS_aln.bcf > alignments/P_MYS_SNPs.vcf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c4319-ca52-4b78-abfc-ce47735179d5",
   "metadata": {},
   "source": [
    "# 3. Make trees using the G and P CDS's\n",
    "\n",
    "```bash\n",
    "fasttree -nt sequences/PG/G_seqs.fasta > trees/G_cds.nwk\n",
    "fasttree -nt sequences/PG/P_seqs.fasta > trees/P_cds.nwk\n",
    "```\n",
    "\n",
    "Another reference: https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionVI/lessons/01_alignment.html\n",
    "\n",
    "# 4. Deduplicate and remake trees\n",
    "\n",
    "## Then remove sequences where more than 1% of the nucleotides are N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f6fe6d-129a-4eb6-a685-77c723e7ce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00221117 0.00718629 0.00773908 0.01050304 0.01547816\n",
      " 0.04256495 0.08181316 0.11111111 0.11719182 0.18794914 0.22443339\n",
      " 0.32172471 0.47263682]\n",
      "[0.         0.00046948 0.0056338  0.00892019 0.01126761 0.08309859]\n"
     ]
    }
   ],
   "source": [
    "# G_seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/G_seqs.fasta\", \"fasta\")]\n",
    "# P_seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/P_seqs.fasta\", \"fasta\")]\n",
    "\n",
    "def count_ambig_nuc(seq):\n",
    "    \n",
    "    count = 0\n",
    "    for char in seq:\n",
    "        if char == \"N\":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# ambig_G = [count_ambig_nuc(seq[1]) for seq in G_seqs]\n",
    "# ambig_P = [count_ambig_nuc(seq[1]) for seq in P_seqs]\n",
    "\n",
    "# print(np.unique(ambig_G) / len(G_seqs[0][1]))\n",
    "# print(np.unique(ambig_P) / len(P_seqs[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e7cdc-e8d8-459d-b06d-97b9c5af1fae",
   "metadata": {},
   "source": [
    "## More sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2adeb7e-dcc5-427c-ac3d-7eadfecf16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_seq(og_fasta):\n",
    "    \n",
    "    seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(og_fasta, \"fasta\")]\n",
    "    \n",
    "    seqs_df = pd.DataFrame(seqs).rename(columns={0:\"ID\", 1:\"Seq\"})\n",
    "\n",
    "    # check that they are sorted alphabetically by ID\n",
    "    assert sum(seqs_df.ID.values != np.sort(seqs_df.ID.values)) == 0\n",
    "\n",
    "    # keeps only the first occurrence. So there are 46 unique glycoprotein sequences and 50 unique phosphoprotein sequences\n",
    "    seqs_df = seqs_df.drop_duplicates(subset=\"Seq\", keep=\"first\")\n",
    "    \n",
    "    for i, row in seqs_df.iterrows():\n",
    "        if count_ambig_nuc(row[\"Seq\"]) / len(row[\"Seq\"]) >= 0.01:\n",
    "            seqs_df.loc[i, \"Ambig\"] = 1\n",
    "\n",
    "    seqs_df[\"Ambig\"] = seqs_df[\"Ambig\"].fillna(0).astype(int)\n",
    "    return seqs_df.query(\"Ambig == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5820b9fa-714b-4eab-85a3-3bf7689669ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_G = deduplicate_seq(\"sequences/PG/G_seqs.fasta\")\n",
    "# with open(\"seq_for_analysis/G_dedup.fasta\", \"w+\") as file:\n",
    "    \n",
    "#     for _, row in keep_G.iterrows():\n",
    "#         file.write(\">\" + row[\"ID\"] + \"\\n\")\n",
    "#         file.write(row[\"Seq\"] + \"\\n\")\n",
    "        \n",
    "# keep_P = deduplicate_seq(\"sequences/PG/P_seqs.fasta\")\n",
    "# with open(\"seq_for_analysis/P_dedup.fasta\", \"w+\") as file:\n",
    "    \n",
    "#     for _, row in keep_P.iterrows():\n",
    "#         file.write(\">\" + row[\"ID\"] + \"\\n\")\n",
    "#         file.write(row[\"Seq\"] + \"\\n\")\n",
    "# keep_G.shape, keep_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d90b4d6-d39d-437f-b7ab-3f568313fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = keep_P.query(\"ID == 'MK673559' | ID == 'AF212302'\").Seq.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbedfde7-510e-4f45-8db5-ec5c3ed5b527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([548]),)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(list(a)) != np.array(list(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09c1b78e-606e-4952-8216-652683000067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3258ed4d-d4c6-4edc-8c62-1518c464019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c669bc7-a618-4c2e-b556-40a82b12f48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
