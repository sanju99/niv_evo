{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c73ebe8-cc31-49ff-a082-924f8cbbf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9479d1-ead5-48b5-bedb-aedb67d94d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malaysian strain genome size: 18246\n"
     ]
    }
   ],
   "source": [
    "#for seq_record in SeqIO.parse(\"sequences/genome/AY029768.1_MYS.fasta\", \"fasta\"):\n",
    "for seq_record in SeqIO.parse(\"sequences/genome/NC_00278.1_MYS.fasta\", \"fasta\"):\n",
    "    \n",
    "    # just wanted to do a sanity check\n",
    "    print(f\"Malaysian strain genome size: {len(seq_record)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae679963-189d-47a6-87e8-40324dbfe8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangaldeshi strain genome size: 18252\n"
     ]
    }
   ],
   "source": [
    "for seq_record in SeqIO.parse(\"sequences/genome/AY988601.1_BGD.fasta\", \"fasta\"):\n",
    "    \n",
    "    # just wanted to do a sanity check\n",
    "    print(f\"Bangaldeshi strain genome size: {len(seq_record)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76692f9-7cdd-4d51-8687-0b9027609539",
   "metadata": {},
   "source": [
    "# 1. BLAST the glycoprotein and phosphoprotein sequences to get all sequences from NCBI\n",
    "\n",
    "Used reference sequences `sequences/PG/ref_G_seq` and `sequences/PG/ref_P_seq` for the glycoprotein and phosphoproteins. Queried these on BLAST using <i>Henipaviruses</i> as the search organism. \n",
    "\n",
    "83 full search results for G (could be individual protein, multiple, or full genome) stored at `sequences/PG/glyco_blast_83.fasta`, and 80 full search results for P stored at `sequences/PG/phospho_blast_80.fasta`. Removed duplicates in Geneious.\n",
    "\n",
    "Descriptions stored at `sequences/glyco_blast_descriptions.csv` and `sequences/phospho_blast_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678a03e-520d-4bc6-9aa4-904f9aef62bf",
   "metadata": {},
   "source": [
    "```bash\n",
    "bowtie2-build sequences/genome/AY029768.1_MYS_CDS.fna MYS_cds\n",
    "bowtie2 -x MYS_cds -f sequences/PG/G_seqs.fasta -S G_aln.sam\n",
    "```\n",
    "\n",
    "The sequence headers were updated, and the V, W, and C proteins were removed because they are duplicates of the phosphoprotein sequence. <b>This was found to cause problems when aligning the glycoprotein sequences</b>. It makes sense that you shouldn't have redundant sequences in a reference sequence, but I'm not sure why it didn't cause problems for the phosphoprotein alignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e78b1ff-bd8c-4c45-9987-c705f2dc8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "glyco_descript = pd.read_csv(\"sequences/glyco_blast_descriptions.csv\")\n",
    "phospho_descript = pd.read_csv(\"sequences/phospho_blast_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d9c1a0-d1db-40a5-aca1-c24e53761367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fName):\n",
    "    \n",
    "    lengths = []\n",
    "    names = []\n",
    "    seqs = []\n",
    "\n",
    "    for seq_record in SeqIO.parse(fName, \"fasta\"):\n",
    "\n",
    "        if \"_\" in seq_record.id:\n",
    "            names.append(seq_record.id.split(\"_\")[0])\n",
    "        else:\n",
    "            names.append(seq_record.id)\n",
    "        seqs.append(seq_record.seq)\n",
    "        lengths.append(len(seq_record))\n",
    "\n",
    "    print(f\"Found {len(seqs)} sequences in {os.path.basename(fName)}\")\n",
    "    \n",
    "    res_dict = dict(zip(np.array(names), seqs))\n",
    "    \n",
    "    return dict(sorted(res_dict.items(), key=lambda x: x[0])), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca1a1d3-b887-40b9-b3cb-adda5e0c414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83 sequences in G_seqs.fasta\n",
      "Found 80 sequences in P_seqs.fasta\n"
     ]
    }
   ],
   "source": [
    "G = read_fasta(\"sequences/PG/G_seqs.fasta\")\n",
    "P = read_fasta(\"sequences/PG/P_seqs.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13a613e-e5be-4dc7-95d3-a4c7ba50c916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JF899340', 'MH891777', 'MN549407', 'MN549410'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(G_low[0].keys()) - set(G[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468beb2-d481-498f-8bec-044c02cfa5ad",
   "metadata": {},
   "source": [
    "# 2. Single nucleotide polymorphism (SNP) calling\n",
    "\n",
    "## End goal is to convert the FASTA file into a VCF (variant calling format) file\n",
    "\n",
    "<b>Amazing tutorial:</b> https://www.ebi.ac.uk/sites/ebi.ac.uk/files/content.ebi.ac.uk/materials/2014/140217_AgriOmics/dan_bolser_snp_calling.pdf\n",
    "\n",
    "## Exact code to run for both P and G aligning to both reference genomes:\n",
    "\n",
    "```bash\n",
    "bash align_make_vcf.sh \"sequences/genome/AY988601.1_BGD_CDS.fna\" \"sequences/PG/P_seqs.fasta\" \"alignments\" \"P_BGD\"\n",
    "bash align_make_vcf.sh \"sequences/genome/NC_00278.1_MYS_CDS.fna\" \"sequences/PG/P_seqs.fasta\" \"alignments\" \"P_MYS\"\n",
    "\n",
    "bash align_make_vcf.sh \"sequences/genome/AY988601.1_BGD_CDS.fna\" \"sequences/PG/G_seqs.fasta\" \"alignments\" \"G_BGD\"\n",
    "bash align_make_vcf.sh \"sequences/genome/NC_00278.1_MYS_CDS.fna\" \"sequences/PG/G_seqs.fasta\" \"alignments\" \"G_MYS\"\n",
    "```\n",
    "\n",
    "The above bash script runs the following steps, adapted from the linked tutorial above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8acc6-9608-4bc2-b7f6-7894c41fa16b",
   "metadata": {},
   "source": [
    "<b></b>\n",
    "```bash\n",
    "bwa index sequences/genome/AY029768.1_MYS_CDS.fna\n",
    "```\n",
    "\n",
    "<b>Perform the alignment</b>\n",
    "```bash\n",
    "bwa aln sequences/genome/AY029768.1_MYS_CDS.fna sequences/PG/P_seqs.fasta > alignments/P_MYS_aln.sai\n",
    "```\n",
    "\n",
    "<b>Convert to SAM file format, which is human-readable</b>\n",
    "```bash\n",
    "bwa samse sequences/genome/AY029768.1_MYS_CDS.fna alignments/P_MYS_aln.sai sequences/PG/P_seqs.fasta > alignments/P_MYS_aln.sam\n",
    "```\n",
    "\n",
    "<b>Convert SAM to BAM and sort the BAM file</b>\n",
    "```bash\n",
    "   samtools view -b alignments/G_BGD_aln.sam > alignments/G_BGD_aln.bam\n",
    "   samtools sort alignments/G_BGD_aln.bam -o alignments/G_BGD_aln_sorted.bam\n",
    "```\n",
    "\n",
    "<b>Index the genome file again with `samtools`</b>\n",
    "```bash\n",
    "samtools faidx sequences/genome/AY029768.1_MYS_CDS.fna\n",
    "```\n",
    "\n",
    "<b>Run 'mpileup' to generate VCF format</b>\n",
    "```bash\n",
    "bcftools mpileup -f sequences/genome/AY988601.1_BGD_CDS.fna alignments/P_MYS_aln_sorted.bam > alignments/P_MYS_aln.bcf\n",
    "```\n",
    "\n",
    "<b>Call SNPs</b>\n",
    "```bash\n",
    "bcftools view -v snps alignments/P_MYS_aln.bcf > alignments/P_MYS_SNPs.vcf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c4319-ca52-4b78-abfc-ce47735179d5",
   "metadata": {},
   "source": [
    "# 3. Make trees using the G and P CDS's\n",
    "\n",
    "```bash\n",
    "fasttree -nt sequences/PG/G_seqs.fasta > trees/G_cds.nwk\n",
    "fasttree -nt sequences/PG/P_seqs.fasta > trees/P_cds.nwk\n",
    "```\n",
    "\n",
    "Another reference: https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionVI/lessons/01_alignment.html\n",
    "\n",
    "# 4. Deduplicate and remake trees -- use all sequences (83 G, 80 P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e0299b-e513-44d3-9c1c-8704547e5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/G_seqs.fasta\", \"fasta\")]\n",
    "P_seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/P_seqs.fasta\", \"fasta\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e7cdc-e8d8-459d-b06d-97b9c5af1fae",
   "metadata": {},
   "source": [
    "## More sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22bf0faf-ebfd-4439-b2e9-bb169429d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "{'AY858111', 'HM545086', 'MH891777', 'AF238467', 'JF899340'}\n",
      "{'MH891774', 'HM545087'}\n"
     ]
    }
   ],
   "source": [
    "G_ids = np.array(list(zip(*G_seqs))[0])\n",
    "P_ids = np.array(list(zip(*P_seqs))[0])\n",
    "\n",
    "# 78 sequences are the same\n",
    "print(len(set(G_ids).intersection(P_ids)))\n",
    "\n",
    "# HM545086, MH891777, JF899340, AF238467, AY858111 are all G only\n",
    "print(set(G_ids) - set(P_ids))\n",
    "\n",
    "# HM545087 is P only. MH891774 is P and C only\n",
    "# MN549407 and MN549410 were the very low quality G sequences that were removed\n",
    "# according to the entries, they are partial genomes isolated from bats, probably explains the low quality\n",
    "print(set(P_ids) - set(G_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d88884-0ee6-4749-881d-84e727f984ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 51)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_G_df = pd.DataFrame(list(zip(*G_seqs))[-1]).rename(columns={0:\"Seq\"})\n",
    "seqs_G_df[\"ID\"] = G_ids\n",
    "\n",
    "seqs_P_df = pd.DataFrame(list(zip(*P_seqs))[-1]).rename(columns={0:\"Seq\"})\n",
    "seqs_P_df[\"ID\"] = P_ids\n",
    "\n",
    "# check that they are sorted alphabetically by ID\n",
    "assert sum(seqs_G_df.ID.values != np.sort(seqs_G_df.ID.values)) == 0\n",
    "assert sum(seqs_P_df.ID.values != np.sort(seqs_P_df.ID.values)) == 0\n",
    "\n",
    "# keeps only the first occurrence. So there are 46 unique glycoprotein sequences and 50 unique phosphoprotein sequences\n",
    "len(seqs_G_df[\"Seq\"].drop_duplicates()), len(seqs_P_df[\"Seq\"].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7edab-d6fd-4be4-88f9-2e397dd987d2",
   "metadata": {},
   "source": [
    "## The next cell writes the unique sequences to new Fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d0f5c1-2114-4fd1-9e42-8b07722ed585",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_G = seqs_G_df.drop_duplicates(\"Seq\")\n",
    "keep_P = seqs_P_df.drop_duplicates(\"Seq\")\n",
    "\n",
    "with open(\"sequences/PG/G_deduplicated.fasta\", \"w+\") as file:\n",
    "    \n",
    "    for _, row in keep_G.iterrows():\n",
    "        file.write(\">\" + row[\"ID\"] + \"\\n\")\n",
    "        file.write(row[\"Seq\"] + \"\\n\")\n",
    "        \n",
    "with open(\"sequences/PG/P_deduplicated.fasta\", \"w+\") as file:\n",
    "    \n",
    "    for _, row in keep_P.iterrows():\n",
    "        file.write(\">\" + row[\"ID\"] + \"\\n\")\n",
    "        file.write(row[\"Seq\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16c9b082-520f-443d-947c-8e9daf464cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dedup = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/G_deduplicated.fasta\", \"fasta\")]\n",
    "P_dedup = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/P_deduplicated.fasta\", \"fasta\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317de71-ffa9-429e-a27c-212c24a162b8",
   "metadata": {},
   "source": [
    "```bash\n",
    "fasttree -nt sequences/PG/G_deduplicated.fasta > trees/G_dedup.nwk\n",
    "fasttree -nt sequences/PG/P_deduplicated.fasta > trees/P_dedup.nwk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8c79162-4b9b-4a1c-8538-d5e81b9f48dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 51)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_dedup), len(P_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c28688c-9cb6-46f0-aa04-408b91c641fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1809] [2130]\n"
     ]
    }
   ],
   "source": [
    "lengths_G = [len(seq) for seq in seqs_G_df.Seq]\n",
    "lengths_P = [len(seq) for seq in seqs_P_df.Seq]\n",
    "\n",
    "print(np.unique(lengths_G), np.unique(lengths_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d2e04-7fa2-42c6-87da-a29e0b4c8efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
