{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c73ebe8-cc31-49ff-a082-924f8cbbf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9479d1-ead5-48b5-bedb-aedb67d94d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malaysian strain genome size: 18246\n"
     ]
    }
   ],
   "source": [
    "#for seq_record in SeqIO.parse(\"sequences/genome/AY029768.1_MYS.fasta\", \"fasta\"):\n",
    "for seq_record in SeqIO.parse(\"sequences/genome/NC_00278.1_MYS.fasta\", \"fasta\"):\n",
    "    \n",
    "    # just wanted to do a sanity check\n",
    "    print(f\"Malaysian strain genome size: {len(seq_record)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae679963-189d-47a6-87e8-40324dbfe8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangaldeshi strain genome size: 18252\n"
     ]
    }
   ],
   "source": [
    "for seq_record in SeqIO.parse(\"sequences/genome/AY988601.1_BGD.fasta\", \"fasta\"):\n",
    "    \n",
    "    # just wanted to do a sanity check\n",
    "    print(f\"Bangaldeshi strain genome size: {len(seq_record)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76692f9-7cdd-4d51-8687-0b9027609539",
   "metadata": {},
   "source": [
    "# 1. BLAST the glycoprotein and phosphoprotein sequences to get all sequences from NCBI\n",
    "\n",
    "Used reference sequences `sequences/PG/ref_G_seq` and `sequences/PG/ref_P_seq` for the glycoprotein and phosphoproteins. Queried these on BLAST using <i>Henipaviruses</i> as the search organism. \n",
    "\n",
    "83 full search results for G (could be individual protein, multiple, or full genome) stored at `sequences/PG/glyco_blast_83.fasta`, and 80 full search results for P stored at `sequences/PG/phospho_blast_80.fasta`. Removed duplicates in Geneious.\n",
    "\n",
    "Descriptions stored at `sequences/glyco_blast_descriptions.csv` and `sequences/phospho_blast_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678a03e-520d-4bc6-9aa4-904f9aef62bf",
   "metadata": {},
   "source": [
    "```bash\n",
    "bowtie2-build sequences/genome/AY029768.1_MYS_CDS.fna MYS_cds\n",
    "bowtie2 -x MYS_cds -f sequences/PG/G_seqs.fasta -S G_aln.sam\n",
    "```\n",
    "\n",
    "The sequence headers were updated, and the V, W, and C proteins were removed because they are duplicates of the phosphoprotein sequence. <b>This was found to cause problems when aligning the glycoprotein sequences</b>. It makes sense that you shouldn't have redundant sequences in a reference sequence, but I'm not sure why it didn't cause problems for the phosphoprotein alignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4b473909-b46a-408b-8b99-eebc9a8abc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_tree_names = [seq_record.id for seq_record in SeqIO.parse(\"sequences/PG/G_seqs.fasta\", \"fasta\")]\n",
    "P_tree_names = [seq_record.id for seq_record in SeqIO.parse(\"sequences/PG/P_seqs.fasta\", \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba3f5bda-c472-4f05-a2b9-5cc32ea1cbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 81)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_tree_names), len(P_tree_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c7b1061f-56eb-4140-815e-78ce051b01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MK577980', 'JF899341', 'MK577985', 'MK577981'}\n",
      "{'NC_002728'}\n"
     ]
    }
   ],
   "source": [
    "P_new = [seq_record.id.split(\".1\")[0].split(\".2\")[0] for seq_record in SeqIO.parse(\"sequences/PG/phospho_blast_84.fasta\", \"fasta\")]\n",
    "\n",
    "print(set(P_new) - set(P_tree_names))\n",
    "print(set(P_tree_names) - set(P_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "611a7cd5-a1f7-44c7-8f22-dc87d1f6c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ncbi_accessions(id_list):\n",
    "    \n",
    "    #Entrez.email='skulkarni@g.harvard.edu'\n",
    "\n",
    "    # search Genbank, returns accession numbers\n",
    "    handle=Entrez.esearch(db='nucleotide', retmax=1000, term=\",\".join(id_list), idtype=\"acc\") \n",
    "    record = Entrez.read(handle)\n",
    "    \n",
    "    handle.close()\n",
    "    fetch = Entrez.efetch(db='nucleotide', id=\",\".join(record['IdList']), rettype='gb', retmode='text')\n",
    "    gb=fetch.read()\n",
    "    \n",
    "    # the first one is an empty string because it's what comes before the first locus\n",
    "    found_seq = list(gb.split(\"LOCUS\"))[1:]\n",
    "    print(f\"Found {len(found_seq)} out of {len(id_list)} NCBI accessions!\")\n",
    "    \n",
    "    # remove the sequences becuase they make the strings unnecessarily long\n",
    "    found_seq = [isolate.split(\"FEATURES\")[0] for isolate in found_seq]\n",
    "    \n",
    "    return found_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9a5184c1-2382-4895-9d98-b779b79b166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 out of 84 NCBI accessions!\n"
     ]
    }
   ],
   "source": [
    "glyco_found = get_ncbi_accessions(G_tree_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "513560c7-cded-46dc-8dc6-172620b0d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81 out of 81 NCBI accessions!\n"
     ]
    }
   ],
   "source": [
    "phospho_found = get_ncbi_accessions(P_tree_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ee679283-9f53-42bb-80b2-8a8c0d55013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "no_date_indices = [i for i in range(len(glyco_found)) if \"VRL\" not in glyco_found[i]]\n",
    "print(no_date_indices)\n",
    "\n",
    "no_date_indices = [i for i in range(len(phospho_found)) if \"VRL\" not in phospho_found[i]]\n",
    "print(no_date_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beca5a5-c44c-424c-8f9f-ddb194da0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict = dict(zip(['India', 'Kerala', 'Malaysia', 'Perak', 'Bangladesh', 'Singapore'], ['India', 'India', 'Malaysia', 'Malaysia', 'Bangladesh', 'Singapore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "87ac09f3-9383-4a17-b16a-8d971d11bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(isolate_lst, ref_lst):\n",
    "    \n",
    "    dates = []\n",
    "#     countries = []\n",
    "    \n",
    "#     no_countries = []\n",
    "    \n",
    "    for isolate in isolate_lst:\n",
    "        \n",
    "        date_index = isolate.index(\"VRL\")\n",
    "        dates.append(isolate[date_index+4:date_index+11+4])\n",
    "        \n",
    "#         found_country = False\n",
    "        \n",
    "#         for country in list(countries_dict.keys()):\n",
    "#             if country in isolate:\n",
    "#                 countries.append(countries_dict[country])\n",
    "#                 found_country = True\n",
    "                \n",
    "#         if not found_country:\n",
    "#             no_countries.append(isolate_lst.index(isolate))\n",
    "        \n",
    "    assert len(dates) == len(isolate_lst) == len(ref_lst)\n",
    "    \n",
    "    return pd.DataFrame({\"Accession\": ref_lst, \"Date\": dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "8ca50ab6-e110-4f62-8a63-ae61022e8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "glyco_date_df = get_dates(glyco_found, G_tree_names)\n",
    "phospho_date_df = get_dates(phospho_found, P_tree_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468beb2-d481-498f-8bec-044c02cfa5ad",
   "metadata": {},
   "source": [
    "# 2. Single nucleotide polymorphism (SNP) calling\n",
    "\n",
    "## End goal is to convert the FASTA file into a VCF (variant calling format) file\n",
    "\n",
    "<b>Amazing tutorial:</b> https://www.ebi.ac.uk/sites/ebi.ac.uk/files/content.ebi.ac.uk/materials/2014/140217_AgriOmics/dan_bolser_snp_calling.pdf\n",
    "\n",
    "## Exact code to run for both P and G aligning to both reference genomes:\n",
    "\n",
    "```bash\n",
    "bash align_make_vcf.sh \"sequences/genome/AY988601.1_BGD_CDS.fna\" \"sequences/PG/P_seqs.fasta\" \"alignments\" \"P_BGD\"\n",
    "bash align_make_vcf.sh \"sequences/genome/NC_00278.1_MYS_CDS.fna\" \"sequences/PG/P_seqs.fasta\" \"alignments\" \"P_MYS\"\n",
    "\n",
    "bash align_make_vcf.sh \"sequences/genome/AY988601.1_BGD_CDS.fna\" \"sequences/PG/G_seqs.fasta\" \"alignments\" \"G_BGD\"\n",
    "bash align_make_vcf.sh \"sequences/genome/NC_00278.1_MYS_CDS.fna\" \"sequences/PG/G_seqs.fasta\" \"alignments\" \"G_MYS\"\n",
    "```\n",
    "\n",
    "The above bash script runs the following steps, adapted from the linked tutorial above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8acc6-9608-4bc2-b7f6-7894c41fa16b",
   "metadata": {},
   "source": [
    "<b></b>\n",
    "```bash\n",
    "bwa index sequences/genome/AY029768.1_MYS_CDS.fna\n",
    "```\n",
    "\n",
    "<b>Perform the alignment</b>\n",
    "```bash\n",
    "bwa aln sequences/genome/AY029768.1_MYS_CDS.fna sequences/PG/P_seqs.fasta > alignments/P_MYS_aln.sai\n",
    "```\n",
    "\n",
    "<b>Convert to SAM file format, which is human-readable</b>\n",
    "```bash\n",
    "bwa samse sequences/genome/AY029768.1_MYS_CDS.fna alignments/P_MYS_aln.sai sequences/PG/P_seqs.fasta > alignments/P_MYS_aln.sam\n",
    "```\n",
    "\n",
    "<b>Convert SAM to BAM and sort the BAM file</b>\n",
    "```bash\n",
    "   samtools view -b alignments/G_BGD_aln.sam > alignments/G_BGD_aln.bam\n",
    "   samtools sort alignments/G_BGD_aln.bam -o alignments/G_BGD_aln_sorted.bam\n",
    "```\n",
    "\n",
    "<b>Index the genome file again with `samtools`</b>\n",
    "```bash\n",
    "samtools faidx sequences/genome/AY029768.1_MYS_CDS.fna\n",
    "```\n",
    "\n",
    "<b>Run 'mpileup' to generate VCF format</b>\n",
    "```bash\n",
    "bcftools mpileup -f sequences/genome/AY988601.1_BGD_CDS.fna alignments/P_MYS_aln_sorted.bam > alignments/P_MYS_aln.bcf\n",
    "```\n",
    "\n",
    "<b>Call SNPs</b>\n",
    "```bash\n",
    "bcftools view -v snps alignments/P_MYS_aln.bcf > alignments/P_MYS_SNPs.vcf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c4319-ca52-4b78-abfc-ce47735179d5",
   "metadata": {},
   "source": [
    "# 3. Make trees using the G and P CDS's\n",
    "\n",
    "```bash\n",
    "fasttree -nt sequences/PG/G_seqs.fasta > trees/G_cds.nwk\n",
    "fasttree -nt sequences/PG/P_seqs.fasta > trees/P_cds.nwk\n",
    "```\n",
    "\n",
    "Another reference: https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionVI/lessons/01_alignment.html\n",
    "\n",
    "# 4. Deduplicate and remake trees -- use all sequences (83 G, 80 P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "44e0299b-e513-44d3-9c1c-8704547e5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/G_seqs.fasta\", \"fasta\")]\n",
    "P_seqs = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/P_seqs.fasta\", \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "44f02e01-3492-4db7-aaa3-1cbf973acf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 81)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_seqs), len(P_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e7cdc-e8d8-459d-b06d-97b9c5af1fae",
   "metadata": {},
   "source": [
    "## More sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "22bf0faf-ebfd-4439-b2e9-bb169429d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "{'JF899340', 'HM545086', 'AY858111', 'AF238467', 'MH891777'}\n",
      "{'HM545087', 'MH891774'}\n"
     ]
    }
   ],
   "source": [
    "G_ids = np.array(list(zip(*G_seqs))[0])\n",
    "P_ids = np.array(list(zip(*P_seqs))[0])\n",
    "\n",
    "# 78 sequences are the same\n",
    "print(len(set(G_ids).intersection(P_ids)))\n",
    "\n",
    "# HM545086, MH891777, JF899340, AF238467, AY858111 are all G only\n",
    "print(set(G_ids) - set(P_ids))\n",
    "\n",
    "# HM545087 is P only. MH891774 is P and C only\n",
    "# MN549407 and MN549410 were the very low quality G sequences that were removed\n",
    "# according to the entries, they are partial genomes isolated from bats, probably explains the low quality\n",
    "print(set(P_ids) - set(G_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "76d88884-0ee6-4749-881d-84e727f984ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 51)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_G_df = pd.DataFrame(list(zip(*G_seqs))[-1]).rename(columns={0:\"Seq\"})\n",
    "seqs_G_df[\"ID\"] = G_ids\n",
    "\n",
    "seqs_P_df = pd.DataFrame(list(zip(*P_seqs))[-1]).rename(columns={0:\"Seq\"})\n",
    "seqs_P_df[\"ID\"] = P_ids\n",
    "\n",
    "# check that they are sorted alphabetically by ID\n",
    "assert sum(seqs_G_df.ID.values != np.sort(seqs_G_df.ID.values)) == 0\n",
    "assert sum(seqs_P_df.ID.values != np.sort(seqs_P_df.ID.values)) == 0\n",
    "\n",
    "# keeps only the first occurrence. So there are 46 unique glycoprotein sequences and 50 unique phosphoprotein sequences\n",
    "len(seqs_G_df[\"Seq\"].drop_duplicates()), len(seqs_P_df[\"Seq\"].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7edab-d6fd-4be4-88f9-2e397dd987d2",
   "metadata": {},
   "source": [
    "## The next cell writes the unique sequences to new Fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "84d0f5c1-2114-4fd1-9e42-8b07722ed585",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_G = seqs_G_df.drop_duplicates(\"Seq\")\n",
    "keep_P = seqs_P_df.drop_duplicates(\"Seq\")\n",
    "\n",
    "with open(\"sequences/PG/G_deduplicated.fasta\", \"w+\") as file:\n",
    "    \n",
    "    for _, row in keep_G.iterrows():\n",
    "        file.write(\">\" + row[\"ID\"] + \"\\n\")\n",
    "        file.write(row[\"Seq\"] + \"\\n\")\n",
    "        \n",
    "with open(\"sequences/PG/P_deduplicated.fasta\", \"w+\") as file:\n",
    "    \n",
    "    for _, row in keep_P.iterrows():\n",
    "        file.write(\">\" + row[\"ID\"] + \"\\n\")\n",
    "        file.write(row[\"Seq\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "16c9b082-520f-443d-947c-8e9daf464cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dedup = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/G_deduplicated.fasta\", \"fasta\")]\n",
    "P_dedup = [(seq_record.id, str(seq_record.seq)) for seq_record in SeqIO.parse(\"sequences/PG/P_deduplicated.fasta\", \"fasta\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317de71-ffa9-429e-a27c-212c24a162b8",
   "metadata": {},
   "source": [
    "```bash\n",
    "fasttree -nt sequences/PG/G_deduplicated.fasta > trees/G_dedup.nwk\n",
    "fasttree -nt sequences/PG/P_deduplicated.fasta > trees/P_dedup.nwk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b8c79162-4b9b-4a1c-8538-d5e81b9f48dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 51)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_dedup), len(P_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8c28688c-9cb6-46f0-aa04-408b91c641fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1809] [2130]\n"
     ]
    }
   ],
   "source": [
    "lengths_G = [len(seq) for seq in seqs_G_df.Seq]\n",
    "lengths_P = [len(seq) for seq in seqs_P_df.Seq]\n",
    "\n",
    "print(np.unique(lengths_G), np.unique(lengths_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "86e8f4ee-986c-43d1-8b59-b79b7f7ea316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phospho_date_df.loc[phospho_date_df[\"Accession\"].isin(list(zip(*P_dedup))[0])].to_csv(\"snp_calling/P_isolates_dates.csv\", index=False)\n",
    "# glyco_date_df.loc[glyco_date_df[\"Accession\"].isin(list(zip(*G_dedup))[0])].to_csv(\"snp_calling/G_isolates_dates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79535edf-a747-4ea5-88b9-a471448a8bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
